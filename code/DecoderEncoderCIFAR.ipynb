{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f17a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import plot_tsne\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from AutoEncoderDecoder import EncoderCIFAR, DecoderCIFAR, ClassifierCIFAR, ProjectionHead,SupConLoss, train_encoder_cifar, plot_reconstruction, plot_images_with_labels, trainEncoderMNIST123\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b351ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', default=0, type=int, help='Seed for random number generators')\n",
    "    parser.add_argument('--data-path', default=\"~/datasets/cv_datasets/data\", type=str, help='Path to dataset')\n",
    "    parser.add_argument('--batch-size', default=8, type=int, help='Size of each batch')\n",
    "    parser.add_argument('--latent-dim', default=128, type=int, help='Encoding dimension')\n",
    "    parser.add_argument('--device', default='cuda' if torch.cuda.is_available() else 'cpu', type=str, help='Default device to use')\n",
    "    parser.add_argument('--mnist', action='store_true', default=False, help='Use MNIST (True) or CIFAR10 (False) data')\n",
    "    parser.add_argument('--self-supervised', action='store_true', default=False, help='Train self-supervised or jointly with classifier')\n",
    "    parser.add_argument('--debug', action='store_true', default=False, help='Enable debugging for dataloader')\n",
    "    args, unknown =  parser.parse_args()\n",
    "    return args\n",
    "\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa1c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_seeds(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5fa4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927db7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_seeds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea1d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "train_dataset = datasets.CIFAR10(root=current_dir, train=True, download=False, transform=transform)\n",
    "class_names = train_dataset.classes \n",
    "test_dataset = datasets.CIFAR10(root=current_dir, train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e83103",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size   = len(train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader \n",
    "# dl_train = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# dl_test  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "# dl_val   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "dl_train = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "dl_test  = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "dl_val   = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "im_size = train_dataset[0][0].shape\n",
    "\n",
    "# Initialize the autoencoder and the optimizer\n",
    "latent_dim = 128\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = EncoderCIFAR(in_channels=im_size[0], latent_dim=128)\n",
    "decoder= DecoderCIFAR(latent_dim=128, out_channels=im_size[0])\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8755af7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m reconstructed \u001b[38;5;241m=\u001b[39m decoder(latent)\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(reconstructed, images)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     18\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Library\\envs\\cs236781-hw\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Library\\envs\\cs236781-hw\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### 1.2.1 Training the autoencoder - selfsupervised ######\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    #train\n",
    "    epoch_loss = 0.0\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    for data in dl_train:\n",
    "        images, _ = data\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        latent = encoder(images)\n",
    "        reconstructed = decoder(latent)\n",
    "        loss = criterion(reconstructed, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(dl_train) \n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_epoch_loss}\")\n",
    "\n",
    "    #validation \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in dl_val:\n",
    "            images, _ = data\n",
    "            images = images.to(device)\n",
    "            latent = encoder(images)\n",
    "            reconstructed = decoder(latent)\n",
    "            loss = criterion(reconstructed, images)\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(dl_val)\n",
    "    print(f\"Ephoch {epoch+1}, Validation Loss: {avg_val_loss}\")\n",
    "    \n",
    "    # Plot reconstructions test images\n",
    "    with torch.no_grad():\n",
    "        test_images, _ = next(iter(dl_test))\n",
    "        test_images = test_images.to(device)\n",
    "        latent = encoder(test_images)\n",
    "        reconstructed = decoder(latent)\n",
    "        \n",
    "        reconstruction_loss = criterion(reconstructed, test_images)\n",
    "        print(f\"Test Reconstruction Loss: {reconstruction_loss.item():.4f}\")\n",
    "        plot_reconstruction(test_images, reconstructed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c302b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in encoder.parameters(): # Freeze encoder weights\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier and optimizer\n",
    "classifier = ClassifierCIFAR(latent_dim=128, num_classes=10).to(device)\n",
    "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "criterion_classifier = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbf075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training classifier\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    classifier.train() \n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data in dl_train:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            latent = encoder(images)\n",
    "\n",
    "        classifier_optimizer.zero_grad() \n",
    "        outputs = classifier(latent) \n",
    "\n",
    "        loss = criterion_classifier(outputs, labels)  # Cross-Entropy Loss\n",
    "        loss.backward()  # Backpropagate\n",
    "        classifier_optimizer.step()  # Update classifier weights\n",
    "\n",
    "        epoch_loss += loss.item()  \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(dl_train)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Validation \n",
    "    classifier.eval()  \n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        for data in dl_val:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            latent = encoder(images)\n",
    "            outputs = classifier(latent)\n",
    "            loss = criterion_classifier(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()  \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(dl_val)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the classifier on the test set\n",
    "classifier.eval() \n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in dl_test:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        latent = encoder(images)\n",
    "        outputs = classifier(latent)\n",
    "\n",
    "        loss = criterion_classifier(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss / len(dl_test):.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "# Visualize the images along with their true and predicted labels\n",
    "plot_images_with_labels(images, labels, predicted, class_names, num_images=10)\n",
    "\n",
    "encoder.eval()  # Set encoder to evaluation mode\n",
    "plot_tsne(encoder, dl_test, device, 'CIFAR_1_2_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c466a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "###1.2.2 - Classification-Guided Encoding###\n",
    "\n",
    "encoder = EncoderCIFAR(in_channels=im_size[0], latent_dim=128) # reset encoder\n",
    "classifier = ClassifierCIFAR(latent_dim=128, num_classes=NUM_CLASSES).to(device) # reset classifier\n",
    "\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(classifier.parameters()), lr=1e-3)\n",
    "criterion_classifier = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop \n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()  # training mode\n",
    "    classifier.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data in dl_train:  \n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        latent = encoder(images)  \n",
    "        outputs = classifier(latent)\n",
    "\n",
    "        loss = criterion_classifier(outputs, labels)\n",
    "        loss.backward() \n",
    "        optimizer.step()  \n",
    "\n",
    "        epoch_loss += loss.item()  \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(dl_train)  \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Validation phase\n",
    "encoder.eval()  \n",
    "classifier.eval()  \n",
    "val_loss = 0.0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for validation\n",
    "    for data in dl_val:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "        latent = encoder(images)\n",
    "        outputs = classifier(latent)\n",
    "            \n",
    "        loss_val = criterion_classifier(outputs, labels)\n",
    "        val_loss += loss_val.item()\n",
    "            \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        val_total += labels.size(0)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "avg_val_loss = val_loss / len(dl_val)\n",
    "val_accuracy = 100 * val_correct / val_total\n",
    "print(f\"Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier on the test set\n",
    "encoder.eval()  \n",
    "classifier.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in dl_test:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        latent = encoder(images)  \n",
    "        outputs = classifier(latent)\n",
    "\n",
    "        loss = criterion_classifier(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss / len(dl_test):.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "# Visualize the images along with their true and predicted labels\n",
    "plot_images_with_labels(images, labels, predicted, class_names, num_images=10)\n",
    "plot_tsne(encoder, dl_test, device, 'CIFAR_1_2_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97cbb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1.2.3 contrastive encoder for CIFAR with SupConLoss\n",
      "Epoch 1/10, Loss: 1.912023\n",
      "Epoch 2/10, Loss: 1.641444\n",
      "Epoch 3/10, Loss: 1.497223\n",
      "Epoch 4/10, Loss: 1.384064\n",
      "Epoch 5/10, Loss: 1.293552\n",
      "Epoch 6/10, Loss: 1.223186\n",
      "Epoch 7/10, Loss: 1.152581\n",
      "Epoch 8/10, Loss: 1.098858\n",
      "Epoch 9/10, Loss: 1.040248\n",
      "Epoch 10/10, Loss: 0.996470\n"
     ]
    }
   ],
   "source": [
    "# ### 1.2.3 ###\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(28, scale=(0.9, 1.0)),  # Crop but keep almost full size\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Only flipping\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "train_dataset = datasets.CIFAR10(root=current_dir, train=True, download=False, transform=transform)\n",
    "class_names = train_dataset.classes \n",
    "test_dataset = datasets.CIFAR10(root=current_dir, train=False, download=False, transform=transform)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size   = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "dl_train = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "dl_test  = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "dl_val   = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "im_size = train_dataset[0][0].shape\n",
    "latent_dim = 128\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # # Train the encoder\n",
    "encoder = EncoderCIFAR(in_channels=im_size[0], latent_dim=128) # reset encoder\n",
    "projection_head = ProjectionHead(in_dim=128, out_dim=128).to(device)\n",
    "# encoder123 = torch.nn.Sequential(encoder, projection_head)\n",
    "train_encoder_cifar(encoder, projection_head, epochs=10, dl_train=dl_train, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d12e6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "Epoch 1, Loss: 0.7933, Accuracy: 73.27%\n",
      "Epoch 1, Validation Loss: 0.8350, Validation Accuracy: 71.25%\n",
      "Epoch 2, Loss: 0.7313, Accuracy: 74.96%\n",
      "Epoch 2, Validation Loss: 0.8302, Validation Accuracy: 71.80%\n",
      "Epoch 3, Loss: 0.7204, Accuracy: 75.19%\n",
      "Epoch 3, Validation Loss: 0.8114, Validation Accuracy: 72.14%\n",
      "Epoch 4, Loss: 0.7158, Accuracy: 75.57%\n",
      "Epoch 4, Validation Loss: 0.8186, Validation Accuracy: 72.47%\n",
      "Epoch 5, Loss: 0.7032, Accuracy: 75.71%\n",
      "Epoch 5, Validation Loss: 0.8312, Validation Accuracy: 71.80%\n",
      "Epoch 6, Loss: 0.7002, Accuracy: 76.00%\n",
      "Epoch 6, Validation Loss: 0.8081, Validation Accuracy: 72.83%\n",
      "Epoch 7, Loss: 0.6995, Accuracy: 75.83%\n",
      "Epoch 7, Validation Loss: 0.8182, Validation Accuracy: 72.48%\n",
      "Epoch 8, Loss: 0.6975, Accuracy: 75.87%\n",
      "Epoch 8, Validation Loss: 0.8146, Validation Accuracy: 71.97%\n",
      "Epoch 9, Loss: 0.6960, Accuracy: 75.86%\n",
      "Epoch 9, Validation Loss: 0.8114, Validation Accuracy: 72.49%\n",
      "Epoch 10, Loss: 0.6924, Accuracy: 76.11%\n",
      "Epoch 10, Validation Loss: 0.8124, Validation Accuracy: 72.67%\n"
     ]
    }
   ],
   "source": [
    "classifier = ClassifierCIFAR(latent_dim=128, num_classes=10).to(device)\n",
    "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "criterion_classifier = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop \n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()  # training mode\n",
    "    classifier.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data in dl_train:  \n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        classifier_optimizer.zero_grad()\n",
    "        latent = encoder(images)\n",
    "        outputs = classifier(latent)\n",
    "\n",
    "        loss = criterion_classifier(outputs, labels)\n",
    "        loss.backward() \n",
    "        classifier_optimizer.step()  \n",
    "\n",
    "        epoch_loss += loss.item()  \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(dl_train)  \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Validation phase\n",
    "    encoder.eval()  \n",
    "    classifier.eval()  \n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        for data in dl_val:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            latent = encoder(images)\n",
    "            outputs = classifier(latent)\n",
    "\n",
    "            loss_val = criterion_classifier(outputs, labels)\n",
    "            val_loss += loss_val.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(dl_val)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    print(f\"Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38355d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8111\n",
      "Test Accuracy: 71.77%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier on the test set\n",
    "encoder.eval()  \n",
    "classifier.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in dl_test:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        latent = encoder(images)  \n",
    "        outputs = classifier(latent)\n",
    "\n",
    "        loss = criterion_classifier(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss / len(dl_test):.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "# Visualize the images along with their true and predicted labels\n",
    "plot_tsne(encoder, dl_test, device, 'CIFAR_1_2_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda1cd27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
